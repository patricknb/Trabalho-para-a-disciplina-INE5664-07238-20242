{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j5CI6TlJF-rB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# ==================== Classe Classificação Multiclasse ====================\n",
        "class ClassificacaoMulticlasse:\n",
        "    def __init__(self, tamanho_entrada, camadas_ocultas, tamanho_saida):\n",
        "        # Inicializa as camadas da rede neural\n",
        "        self.tamanho_entrada = tamanho_entrada\n",
        "        self.camadas_ocultas = camadas_ocultas\n",
        "        self.tamanho_saida = tamanho_saida\n",
        "\n",
        "        self.pesos = []\n",
        "        self.biases = []\n",
        "\n",
        "        # Inicialização das camadas com valores aleatórios\n",
        "        self.pesos.append(np.random.randn(tamanho_entrada, camadas_ocultas[0]) * np.sqrt(2. / tamanho_entrada))\n",
        "        self.biases.append(np.zeros((1, camadas_ocultas[0])))\n",
        "\n",
        "        for i in range(1, len(camadas_ocultas)):\n",
        "            self.pesos.append(np.random.randn(camadas_ocultas[i-1], camadas_ocultas[i]) * np.sqrt(2. / camadas_ocultas[i-1]))\n",
        "            self.biases.append(np.zeros((1, camadas_ocultas[i])))\n",
        "\n",
        "        self.pesos.append(np.random.randn(camadas_ocultas[-1], tamanho_saida) * np.sqrt(2. / camadas_ocultas[-1]))\n",
        "        self.biases.append(np.zeros((1, tamanho_saida)))\n",
        "\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def relu_derivada(self, x):\n",
        "        return (x > 0).astype(int)\n",
        "\n",
        "    def softmax(self, x):\n",
        "        # Função softmax para ativação da camada de saída\n",
        "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "    def cross_entropy(self, y_pred, y_true):\n",
        "        # Função de perda: Entropia cruzada\n",
        "        m = y_true.shape[0]\n",
        "        epsilon = 1e-8  # Para evitar log(0)\n",
        "        return -np.sum(y_true * np.log(y_pred + epsilon)) / m\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.activations = []\n",
        "        self.z_values = []\n",
        "\n",
        "        # Propagação para frente\n",
        "        z = np.dot(X, self.pesos[0]) + self.biases[0]\n",
        "        a = self.relu(z)\n",
        "        self.activations.append(a)\n",
        "        self.z_values.append(z)\n",
        "\n",
        "        for i in range(1, len(self.camadas_ocultas)):\n",
        "            z = np.dot(self.activations[-1], self.pesos[i]) + self.biases[i]\n",
        "            a = self.relu(z)\n",
        "            self.activations.append(a)\n",
        "            self.z_values.append(z)\n",
        "\n",
        "        z_output = np.dot(self.activations[-1], self.pesos[-1]) + self.biases[-1]\n",
        "        y_pred = self.softmax(z_output)\n",
        "        self.activations.append(y_pred)\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def backpropagate(self, X, y, taxa_aprendizado):\n",
        "        m = X.shape[0]\n",
        "\n",
        "        gradiente_saida = self.activations[-1] - y\n",
        "        # Atualização dos pesos e vieses na camada de saída\n",
        "        self.pesos[-1] -= np.dot(self.activations[-2].T, gradiente_saida) * taxa_aprendizado / m\n",
        "        self.biases[-1] -= np.sum(gradiente_saida, axis=0, keepdims=True) * taxa_aprendizado / m\n",
        "\n",
        "        gradiente = gradiente_saida\n",
        "        # Retropropagação para as camadas ocultas\n",
        "        for i in range(len(self.camadas_ocultas) - 1, -1, -1):\n",
        "            gradiente = np.dot(gradiente, self.pesos[i+1].T) * self.relu_derivada(self.z_values[i])\n",
        "            if i > 0:\n",
        "                self.pesos[i] -= np.dot(self.activations[i-1].T, gradiente) * taxa_aprendizado / m\n",
        "                self.biases[i] -= np.sum(gradiente, axis=0, keepdims=True) * taxa_aprendizado / m\n",
        "            else:\n",
        "                self.pesos[i] -= np.dot(X.T, gradiente) * taxa_aprendizado / m\n",
        "                self.biases[i] -= np.sum(gradiente, axis=0, keepdims=True) * taxa_aprendizado / m\n",
        "\n",
        "    def train(self, X, y, epocas, batch_size, taxa_aprendizado):\n",
        "        for epoca in range(epocas):\n",
        "            for i in range(0, len(X), batch_size):\n",
        "                X_batch = X[i:i+batch_size]\n",
        "                y_batch = y[i:i+batch_size]\n",
        "\n",
        "                y_pred = self.forward(X_batch)\n",
        "                custo = self.cross_entropy(y_pred, y_batch)\n",
        "                self.backpropagate(X_batch, y_batch, taxa_aprendizado)\n",
        "\n",
        "            if epoca % 100 == 0 or epoca == epocas-1:\n",
        "                # Calcular a precisão nos dados de treino durante o treinamento\n",
        "                metrics = self.evaluate(X, y)\n",
        "                print(f'Época {epoca}, Custo: {custo:.4f}, Acurácia: {metrics[\"Accuracy\"]:.2%} Precisão no treino: {metrics[\"Precision\"]:.2%}, Recall: {metrics[\"Recall\"]:.2%}, F1-score: {metrics[\"F1-Score\"]:.2%}')\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        # Avalia a precisão do modelo com métricas adicionais\n",
        "        y_pred = self.forward(X)  # Probabilidades previstas\n",
        "        predictions = np.argmax(y_pred, axis=1)  # Classes previstas\n",
        "        true_labels = np.argmax(y, axis=1)  # Classes reais\n",
        "\n",
        "        # Inicializar variáveis para métricas\n",
        "        classes = np.unique(true_labels)\n",
        "        precisions, recalls, f1_scores = [], [], []\n",
        "\n",
        "        for c in classes:\n",
        "            TP = np.sum((predictions == c) & (true_labels == c))  # Verdadeiros Positivos para a classe c\n",
        "            FP = np.sum((predictions == c) & (true_labels != c))  # Falsos Positivos para a classe c\n",
        "            FN = np.sum((predictions != c) & (true_labels == c))  # Falsos Negativos para a classe c\n",
        "\n",
        "            precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "            recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "            precisions.append(precision)\n",
        "            recalls.append(recall)\n",
        "            f1_scores.append(f1_score)\n",
        "\n",
        "        # Cálculo das médias (média macro)\n",
        "        avg_precision = np.mean(precisions)\n",
        "        avg_recall = np.mean(recalls)\n",
        "        avg_f1_score = np.mean(f1_scores)\n",
        "        accuracy = np.mean(predictions == true_labels)\n",
        "\n",
        "        # Retorno como dicionário\n",
        "        metrics = {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision': avg_precision,\n",
        "            'Recall': avg_recall,\n",
        "            'F1-Score': avg_f1_score\n",
        "        }\n",
        "        return metrics\n",
        "\n",
        "    # Salvar pesos e bias\n",
        "    def save_pesos(self, file_path):\n",
        "        # Salva pesos e bias com nomes claros para cada camada\n",
        "        np.savez(file_path,\n",
        "                pesos_0=self.pesos[0], biases_0=self.biases[0],\n",
        "                pesos_1=self.pesos[1], biases_1=self.biases[1],\n",
        "                pesos_2=self.pesos[2], biases_2=self.biases[2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RAuN7CU7F-rD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ==================== Funções de Carregamento e Pré-processamento ====================\n",
        "def normalizar_dados(entradas):\n",
        "    # Normalização: traz os dados para a mesma escala\n",
        "    desvio_padrao = entradas.std(axis=0)\n",
        "    desvio_padrao[desvio_padrao == 0] = 1  # Evita divisão por zero\n",
        "    return (entradas - entradas.mean(axis=0)) / desvio_padrao\n",
        "\n",
        "# ==================== Execução do Modelo ====================\n",
        "# 1. Carregar os dados de treinamento\n",
        "caminho_arquivo_treino = 'train_esrb_rating.csv'\n",
        "dados = pd.read_csv(caminho_arquivo_treino)\n",
        "\n",
        "# Separar entradas e rótulos\n",
        "entradas = dados.iloc[:, :-1].values  # Todas as colunas, exceto a última\n",
        "rotulos = dados.iloc[:, -1].values    # Última coluna (os rótulos de classe)\n",
        "\n",
        "# 2. Pré-processamento para os dados de treinamento\n",
        "entradas_normalizadas = normalizar_dados(entradas)\n",
        "rotulos_one_hot = pd.get_dummies(rotulos).values  # One-hot encoding para as classes\n",
        "\n",
        "# 3. Definir a arquitetura da rede neural\n",
        "tamanho_entrada = entradas_normalizadas.shape[1]\n",
        "tamanho_saida = rotulos_one_hot.shape[1]\n",
        "camadas_ocultas = [10, 10, 10]  # Número de neurônios nas camadas ocultas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oHy4-y4YF-rD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Inicializar a rede neural\n",
        "nn = ClassificacaoMulticlasse(tamanho_entrada, camadas_ocultas, tamanho_saida)\n",
        "\n",
        "# 4. Carregar os dados de teste\n",
        "caminho_arquivo_teste = 'test_esrb_rating.csv'\n",
        "dados_teste = pd.read_csv(caminho_arquivo_teste)\n",
        "\n",
        "# Separar entradas e rótulos para o teste\n",
        "entradas_teste = dados_teste.iloc[:, :-1].values\n",
        "rotulos_teste = dados_teste.iloc[:, -1].values\n",
        "\n",
        "# 5. Pré-processamento para os dados de teste\n",
        "entradas_teste_normalizadas = normalizar_dados(entradas_teste)\n",
        "rotulos_teste_one_hot = pd.get_dummies(rotulos_teste).values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYjVMbfQF-rE",
        "outputId": "b3351ca2-a79c-476f-83b6-88e4d04998ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 0, Custo: 1.5641, Acurácia: 25.50% Precisão no treino: 17.45%, Recall: 22.01%, F1-score: 19.32%\n",
            "Época 100, Custo: 1.2082, Acurácia: 53.80% Precisão no treino: 53.03%, Recall: 51.20%, F1-score: 48.46%\n",
            "Época 200, Custo: 1.0609, Acurácia: 62.46% Precisão no treino: 65.72%, Recall: 60.69%, F1-score: 60.03%\n",
            "Época 300, Custo: 0.9253, Acurácia: 66.53% Precisão no treino: 67.12%, Recall: 65.87%, F1-score: 64.99%\n",
            "Época 400, Custo: 0.8068, Acurácia: 69.22% Precisão no treino: 70.25%, Recall: 68.33%, F1-score: 67.67%\n",
            "Época 500, Custo: 0.7144, Acurácia: 76.08% Precisão no treino: 77.36%, Recall: 76.05%, F1-score: 76.37%\n",
            "Época 600, Custo: 0.6419, Acurácia: 77.61% Precisão no treino: 78.60%, Recall: 77.77%, F1-score: 77.96%\n",
            "Época 700, Custo: 0.5824, Acurácia: 81.20% Precisão no treino: 81.89%, Recall: 81.91%, F1-score: 81.89%\n",
            "Época 800, Custo: 0.5374, Acurácia: 82.37% Precisão no treino: 82.75%, Recall: 83.25%, F1-score: 82.98%\n",
            "Época 900, Custo: 0.5011, Acurácia: 83.47% Precisão no treino: 83.94%, Recall: 84.23%, F1-score: 84.08%\n",
            "Época 1000, Custo: 0.4721, Acurácia: 83.95% Precisão no treino: 84.22%, Recall: 84.88%, F1-score: 84.52%\n",
            "Época 1100, Custo: 0.4481, Acurácia: 84.21% Precisão no treino: 84.52%, Recall: 85.03%, F1-score: 84.75%\n",
            "Época 1200, Custo: 0.4280, Acurácia: 84.48% Precisão no treino: 84.85%, Recall: 85.39%, F1-score: 85.09%\n",
            "Época 1300, Custo: 0.4101, Acurácia: 84.53% Precisão no treino: 84.86%, Recall: 85.48%, F1-score: 85.13%\n",
            "Época 1400, Custo: 0.3943, Acurácia: 84.95% Precisão no treino: 85.30%, Recall: 85.96%, F1-score: 85.58%\n",
            "Época 1500, Custo: 0.3808, Acurácia: 85.22% Precisão no treino: 85.58%, Recall: 86.21%, F1-score: 85.84%\n",
            "Época 1600, Custo: 0.3692, Acurácia: 85.96% Precisão no treino: 86.26%, Recall: 87.00%, F1-score: 86.55%\n",
            "Época 1700, Custo: 0.3599, Acurácia: 86.11% Precisão no treino: 86.40%, Recall: 87.13%, F1-score: 86.69%\n",
            "Época 1800, Custo: 0.3520, Acurácia: 86.11% Precisão no treino: 86.49%, Recall: 87.13%, F1-score: 86.74%\n",
            "Época 1900, Custo: 0.3450, Acurácia: 86.69% Precisão no treino: 87.01%, Recall: 87.75%, F1-score: 87.31%\n",
            "Época 2000, Custo: 0.3385, Acurácia: 86.85% Precisão no treino: 87.19%, Recall: 87.86%, F1-score: 87.47%\n",
            "Época 2100, Custo: 0.3329, Acurácia: 87.17% Precisão no treino: 87.51%, Recall: 88.13%, F1-score: 87.77%\n",
            "Época 2200, Custo: 0.3280, Acurácia: 87.54% Precisão no treino: 87.87%, Recall: 88.42%, F1-score: 88.10%\n",
            "Época 2300, Custo: 0.3232, Acurácia: 88.17% Precisão no treino: 88.46%, Recall: 88.97%, F1-score: 88.69%\n",
            "Época 2400, Custo: 0.3190, Acurácia: 88.38% Precisão no treino: 88.67%, Recall: 89.20%, F1-score: 88.90%\n",
            "Época 2500, Custo: 0.3149, Acurácia: 88.44% Precisão no treino: 88.74%, Recall: 89.23%, F1-score: 88.96%\n",
            "Época 2600, Custo: 0.3113, Acurácia: 88.44% Precisão no treino: 88.74%, Recall: 89.23%, F1-score: 88.96%\n",
            "Época 2700, Custo: 0.3080, Acurácia: 88.44% Precisão no treino: 88.74%, Recall: 89.23%, F1-score: 88.96%\n",
            "Época 2800, Custo: 0.3052, Acurácia: 88.86% Precisão no treino: 89.17%, Recall: 89.60%, F1-score: 89.35%\n",
            "Época 2900, Custo: 0.3024, Acurácia: 88.86% Precisão no treino: 89.18%, Recall: 89.60%, F1-score: 89.36%\n",
            "Época 3000, Custo: 0.2997, Acurácia: 88.91% Precisão no treino: 89.23%, Recall: 89.67%, F1-score: 89.41%\n",
            "Época 3100, Custo: 0.2974, Acurácia: 89.02% Precisão no treino: 89.35%, Recall: 89.74%, F1-score: 89.51%\n",
            "Época 3200, Custo: 0.2952, Acurácia: 89.07% Precisão no treino: 89.37%, Recall: 89.80%, F1-score: 89.56%\n",
            "Época 3300, Custo: 0.2933, Acurácia: 89.02% Precisão no treino: 89.32%, Recall: 89.77%, F1-score: 89.51%\n",
            "Época 3400, Custo: 0.2914, Acurácia: 89.02% Precisão no treino: 89.33%, Recall: 89.77%, F1-score: 89.52%\n",
            "Época 3500, Custo: 0.2896, Acurácia: 88.97% Precisão no treino: 89.27%, Recall: 89.75%, F1-score: 89.48%\n",
            "Época 3600, Custo: 0.2878, Acurácia: 88.97% Precisão no treino: 89.27%, Recall: 89.75%, F1-score: 89.48%\n",
            "Época 3700, Custo: 0.2861, Acurácia: 89.07% Precisão no treino: 89.38%, Recall: 89.83%, F1-score: 89.57%\n",
            "Época 3800, Custo: 0.2845, Acurácia: 89.12% Precisão no treino: 89.43%, Recall: 89.86%, F1-score: 89.62%\n",
            "Época 3900, Custo: 0.2828, Acurácia: 89.12% Precisão no treino: 89.43%, Recall: 89.86%, F1-score: 89.62%\n",
            "Época 4000, Custo: 0.2812, Acurácia: 89.18% Precisão no treino: 89.52%, Recall: 89.90%, F1-score: 89.68%\n",
            "Época 4100, Custo: 0.2797, Acurácia: 89.18% Precisão no treino: 89.52%, Recall: 89.90%, F1-score: 89.68%\n",
            "Época 4200, Custo: 0.2782, Acurácia: 89.28% Precisão no treino: 89.61%, Recall: 90.02%, F1-score: 89.78%\n",
            "Época 4300, Custo: 0.2768, Acurácia: 89.28% Precisão no treino: 89.55%, Recall: 90.20%, F1-score: 89.81%\n",
            "Época 4400, Custo: 0.2754, Acurácia: 89.28% Precisão no treino: 89.55%, Recall: 90.20%, F1-score: 89.81%\n",
            "Época 4500, Custo: 0.2741, Acurácia: 89.33% Precisão no treino: 89.62%, Recall: 90.24%, F1-score: 89.87%\n",
            "Época 4600, Custo: 0.2727, Acurácia: 89.33% Precisão no treino: 89.62%, Recall: 90.24%, F1-score: 89.87%\n",
            "Época 4700, Custo: 0.2713, Acurácia: 89.33% Precisão no treino: 89.62%, Recall: 90.24%, F1-score: 89.87%\n",
            "Época 4800, Custo: 0.2700, Acurácia: 89.44% Precisão no treino: 89.71%, Recall: 90.34%, F1-score: 89.96%\n",
            "Época 4900, Custo: 0.2687, Acurácia: 89.49% Precisão no treino: 89.77%, Recall: 90.38%, F1-score: 90.01%\n",
            "Época 4999, Custo: 0.2673, Acurácia: 89.55% Precisão no treino: 89.83%, Recall: 90.39%, F1-score: 90.06%\n",
            "==Teste==\n",
            "Acurácia: 84.57%\n",
            "Precisão: 85.22%\n",
            "Recall: 85.45%\n",
            "F1-Score: 85.29%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 6. Treinamento do modelo\n",
        "epocas = 5000\n",
        "batch_size = len(entradas_normalizadas)  # Usando todos os dados para o treinamento\n",
        "taxa_aprendizado = 0.01\n",
        "nn.train(entradas_normalizadas, rotulos_one_hot, epocas, batch_size, taxa_aprendizado)\n",
        "\n",
        "# 7. Salvar os pesos após o treinamento\n",
        "seconds = time.time()\n",
        "nn.save_pesos(f'modelo_classificacao_multiclasse-{time.ctime(seconds)}.npz')\n",
        "\n",
        "# 8. Avaliar o modelo com os dados de teste\n",
        "metrics = nn.evaluate(entradas_teste_normalizadas, rotulos_teste_one_hot)\n",
        "print('==Teste==')\n",
        "print(f\"Acurácia: {metrics['Accuracy']:.2%}\")\n",
        "print(f\"Precisão: {metrics['Precision']:.2%}\")\n",
        "print(f\"Recall: {metrics['Recall']:.2%}\")\n",
        "print(f\"F1-Score: {metrics['F1-Score']:.2%}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo de classificação multiclasse\n",
    "\n",
    "Este notebook utiliza um conjunto de dados que contém informações sobre 1.895 jogos eletrônicos e suas classificações de conteúdo conforme o sistema ESRB (Entertainment Software Rating Board). \n",
    "\n",
    "Objetivo\n",
    "\n",
    "O modelo busca identificar a classificação de um jogo em categorias como \"E\" (Everyone), \"ET\" (Everyone + plus), \"T\" (Teen) e \"M\" (Mature), usando técnicas de aprendizado de máquina. A classificação correta pode ajudar desenvolvedores, distribuidores e consumidores a compreender o público-alvo de um jogo.\n",
    "\n",
    "Estrutura dos Dados\n",
    "\n",
    "Os dados são compostos pelos seguintes atributos:\n",
    "\n",
    "    title \tstring \tName of the game. \t----\n",
    "\n",
    "    console \tint \tThe console on which the game was released. \t0 = PS4 1 = PS4 & Xbox_one\n",
    "\n",
    "    Alcohol_Reference \tint \tReference to and/or images of alcoholic beverages. \t0 = no 1 = yes\n",
    "\n",
    "    Animated_Blood \tint \tDiscolored and/or unrealistic depictions of blood. \t0 = no 1 = yes\n",
    "\n",
    "    Blood \tint \tDepictions of blood. \t0 = no 1 = yes\n",
    "\n",
    "    Blood_and_Gore \tint \tDepictions of blood or the mutilation of body parts. \t0 = no 1 = yes\n",
    "\n",
    "    Cartoon_Violence \tint \tViolent actions involving cartoon-like situations and characters. May include violence where a character is unharmed after the action has been inflicted. \t0 = no 1 = yes\n",
    "\n",
    "    Crude_Humor \tint \tDepictions or dialogue involving vulgar antics, including \"bathroom\" humor. \t0 = no 1 = yes\n",
    "\n",
    "    DrugRe_ference \tint \tReference to and/or images of illegal drugs. \t0 = no 1 = yes\n",
    "\n",
    "    Fantasy_Violence \tint \tViolent actions of a fantasy nature, involving human or non-human characters in situations easily distinguishable from real life. \t0 = no 1 = yes\n",
    "\n",
    "    Intense_Violence \tint \tGraphic and realistic-looking depictions of physical conflict. May involve extreme and/or realistic blood, gore, weapons, and depictions of human injury and death. \t0 = no 1 = yes\n",
    "\n",
    "    Language \tint \tModerate use of profanity. \t0 = no 1 = yes\n",
    "\n",
    "    Lyrics \tint \tReferences to profanity, sexuality, violence, alcohol, or drug use in music. \t0 = no 1 = yes\n",
    "\n",
    "    Mature_Humor \tint \tDepictions or dialogue involving \"adult\" humor, including sexual references. \t0 = no 1 = yes\n",
    "\n",
    "    Mild_Blood \tint \tSome blood. \t0 = no 1 = yes\n",
    "\n",
    "    Mild_Cartoon_Violence \tint \tSome violent actions involving cartoon. \t0 = no 1 = yes\n",
    "\n",
    "    Mild_Fantasy_Violence \tint \tSome violent actions of a fantasy nature. \t0 = no 1 = yes\n",
    "\n",
    "    Mild_Language \tint \tMild to moderate use of profanity. \t0 = no 1 = yes\n",
    "\n",
    "    Mild_Lyrics \tint \tMild References to profanity, sexuality, violence, alcohol, or drug use in music. \t0 = no 1 = yes\n",
    "\n",
    "    Mild_Suggestive_Themes \tint \tsome provocative references or materials \t0 = no 1 = yes\n",
    "\n",
    "    Mild_Violence \tint \tSome scenes involving aggressive conflict. \t0 = no 1 = yes\n",
    "\n",
    "    No_Descriptors \tint \tNo content descriptors. \t0 = no 1 = yes\n",
    "\n",
    "    Nudity \tint \tGraphic or prolonged depictions of nudity. \t0 = no 1 = yes\n",
    "\n",
    "    Partial_Nudity \tint \tBrief and/or mild depictions of nudity. \t0 = no 1 = yes\n",
    "\n",
    "    Sexual_Content \tint \tNon-explicit depictions of sexual behavior, possibly including partial nudity. \t0 = no 1 = yes\n",
    "\n",
    "    Sexual_Themes \tint \tReferences to sex or sexuality. \t0 = no 1 = yes\n",
    "\n",
    "    Simulated_Gambling \tint \tPlayer can gamble without betting or wagering real cash or currency. \t0 = no 1 = yes\n",
    "\n",
    "    Strong_Language \tint \tExplicit and/or frequent use of profanity. \t0 = no 1 = yes\n",
    "\n",
    "    Strong_Sexual_Content \tint \tExplicit and/or frequent depictions of sexual behavior, possibly including nudity. \t0 = no 1 = yes\n",
    "\n",
    "    Suggestive_Themes \tint \tProvocative references or materials. \t0 = no 1 = yes\n",
    "\n",
    "    Use_of_Alcohol \tint \tThe consumption of alcoholic beverages. \t0 = no 1 = yes\n",
    "\n",
    "    Use_of_Drugs_and_Alcohol \tint \tThe consumption of alcoholic and drugs beverages. \t0 = no 1 = yes\n",
    "\n",
    "    Violence \tint \tScenes involving aggressive conflict. May contain bloodless dismemberment. \t0 = no 1 = yes\n",
    "\n",
    "Rotulo\n",
    "\n",
    "    ESRB_rating \tstring \trating: RP - EC - E - E+10 - T - M - A    \tE , ET , T , M\n",
    "\n",
    "Limitações dos Dados\n",
    "\n",
    "Algumas classificações como \"RP\" (Rating Pending), \"EC\" (Early Childhood) e \"A\" (Adults Only) não estão presentes na versão atual do conjunto de dados, limitando a abrangência do modelo.\n",
    "\n",
    "Abordagem\n",
    "\n",
    "Para implementar o modelo foi algoritmos de aprendizado supervisionado para:\n",
    "    \n",
    "    Algoritmo de retropropagação (backpropagation);\n",
    "    Otimização por gradiente descendente.\n",
    "\n",
    "\n",
    "Essa análise pode ser estendida para melhorar recomendações e garantir conformidade com as diretrizes da ESRB. Caso precise de mais informações ou análises, posso ajudar!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "j5CI6TlJF-rB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# ==================== Classe Classificação Multiclasse ====================\n",
    "class ClassificacaoMulticlasse:\n",
    "    def __init__(self, tamanho_entrada, camadas_ocultas, tamanho_saida):\n",
    "        # Inicializa as camadas da rede neural\n",
    "        self.tamanho_entrada = tamanho_entrada\n",
    "        self.camadas_ocultas = camadas_ocultas\n",
    "        self.tamanho_saida = tamanho_saida\n",
    "\n",
    "        self.pesos = []\n",
    "        self.biases = []\n",
    "\n",
    "        # Inicialização das camadas com valores aleatórios\n",
    "        self.pesos.append(np.random.randn(tamanho_entrada, camadas_ocultas[0]) * np.sqrt(2. / tamanho_entrada))\n",
    "        self.biases.append(np.zeros((1, camadas_ocultas[0])))\n",
    "\n",
    "        for i in range(1, len(camadas_ocultas)):\n",
    "            self.pesos.append(np.random.randn(camadas_ocultas[i-1], camadas_ocultas[i]) * np.sqrt(2. / camadas_ocultas[i-1]))\n",
    "            self.biases.append(np.zeros((1, camadas_ocultas[i])))\n",
    "\n",
    "        self.pesos.append(np.random.randn(camadas_ocultas[-1], tamanho_saida) * np.sqrt(2. / camadas_ocultas[-1]))\n",
    "        self.biases.append(np.zeros((1, tamanho_saida)))\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def relu_derivada(self, x):\n",
    "        return (x > 0).astype(int)\n",
    "\n",
    "    def softmax(self, x):\n",
    "        # Função softmax para ativação da camada de saída\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "    def cross_entropy(self, y_pred, y_true):\n",
    "        # Função de perda: Entropia cruzada\n",
    "        m = y_true.shape[0]\n",
    "        epsilon = 1e-8  # Para evitar log(0)\n",
    "        return -np.sum(y_true * np.log(y_pred + epsilon)) / m\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.activations = []\n",
    "        self.z_values = []\n",
    "\n",
    "        # Propagação para frente\n",
    "        z = np.dot(X, self.pesos[0]) + self.biases[0]\n",
    "        a = self.relu(z)\n",
    "        self.activations.append(a)\n",
    "        self.z_values.append(z)\n",
    "\n",
    "        for i in range(1, len(self.camadas_ocultas)):\n",
    "            z = np.dot(self.activations[-1], self.pesos[i]) + self.biases[i]\n",
    "            a = self.relu(z)\n",
    "            self.activations.append(a)\n",
    "            self.z_values.append(z)\n",
    "\n",
    "        z_output = np.dot(self.activations[-1], self.pesos[-1]) + self.biases[-1]\n",
    "        y_pred = self.softmax(z_output)\n",
    "        self.activations.append(y_pred)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def backpropagate(self, X, y, taxa_aprendizado):\n",
    "        m = X.shape[0]\n",
    "\n",
    "        gradiente_saida = self.activations[-1] - y\n",
    "        # Atualização dos pesos e vieses na camada de saída\n",
    "        self.pesos[-1] -= np.dot(self.activations[-2].T, gradiente_saida) * taxa_aprendizado / m\n",
    "        self.biases[-1] -= np.sum(gradiente_saida, axis=0, keepdims=True) * taxa_aprendizado / m\n",
    "\n",
    "        gradiente = gradiente_saida\n",
    "        # Retropropagação para as camadas ocultas\n",
    "        for i in range(len(self.camadas_ocultas) - 1, -1, -1):\n",
    "            gradiente = np.dot(gradiente, self.pesos[i+1].T) * self.relu_derivada(self.z_values[i])\n",
    "            if i > 0:\n",
    "                self.pesos[i] -= np.dot(self.activations[i-1].T, gradiente) * taxa_aprendizado / m\n",
    "                self.biases[i] -= np.sum(gradiente, axis=0, keepdims=True) * taxa_aprendizado / m\n",
    "            else:\n",
    "                self.pesos[i] -= np.dot(X.T, gradiente) * taxa_aprendizado / m\n",
    "                self.biases[i] -= np.sum(gradiente, axis=0, keepdims=True) * taxa_aprendizado / m\n",
    "\n",
    "    def train(self, X, y, epocas, batch_size, taxa_aprendizado):\n",
    "        for epoca in range(epocas):\n",
    "            for i in range(0, len(X), batch_size):\n",
    "                X_batch = X[i:i+batch_size]\n",
    "                y_batch = y[i:i+batch_size]\n",
    "\n",
    "                y_pred = self.forward(X_batch)\n",
    "                custo = self.cross_entropy(y_pred, y_batch)\n",
    "                self.backpropagate(X_batch, y_batch, taxa_aprendizado)\n",
    "\n",
    "            if epoca % 100 == 0 or epoca == epocas-1:\n",
    "                # Calcular a precisão nos dados de treino durante o treinamento\n",
    "                metrics = self.evaluate(X, y)\n",
    "                print(f'Época {epoca}, Custo: {custo:.4f}, Acurácia: {metrics[\"Accuracy\"]:.2%} Precisão no treino: {metrics[\"Precision\"]:.2%}, Recall: {metrics[\"Recall\"]:.2%}, F1-score: {metrics[\"F1-Score\"]:.2%}')\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        # Avalia a precisão do modelo com métricas adicionais\n",
    "        y_pred = self.forward(X)  # Probabilidades previstas\n",
    "        predictions = np.argmax(y_pred, axis=1)  # Classes previstas\n",
    "        true_labels = np.argmax(y, axis=1)  # Classes reais\n",
    "\n",
    "        # Inicializar variáveis para métricas\n",
    "        classes = np.unique(true_labels)\n",
    "        precisions, recalls, f1_scores = [], [], []\n",
    "\n",
    "        for c in classes:\n",
    "            TP = np.sum((predictions == c) & (true_labels == c))  # Verdadeiros Positivos para a classe c\n",
    "            FP = np.sum((predictions == c) & (true_labels != c))  # Falsos Positivos para a classe c\n",
    "            FN = np.sum((predictions != c) & (true_labels == c))  # Falsos Negativos para a classe c\n",
    "\n",
    "            precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "            recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1_scores.append(f1_score)\n",
    "\n",
    "        # Cálculo das médias (média macro)\n",
    "        avg_precision = np.mean(precisions)\n",
    "        avg_recall = np.mean(recalls)\n",
    "        avg_f1_score = np.mean(f1_scores)\n",
    "        accuracy = np.mean(predictions == true_labels)\n",
    "\n",
    "        # Retorno como dicionário\n",
    "        metrics = {\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': avg_precision,\n",
    "            'Recall': avg_recall,\n",
    "            'F1-Score': avg_f1_score\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "    # Salvar pesos e bias\n",
    "    def save_pesos(self, file_path):\n",
    "        # Salva pesos e bias com nomes claros para cada camada\n",
    "        np.savez(file_path,\n",
    "                pesos_0=self.pesos[0], biases_0=self.biases[0],\n",
    "                pesos_1=self.pesos[1], biases_1=self.biases[1],\n",
    "                pesos_2=self.pesos[2], biases_2=self.biases[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RAuN7CU7F-rD"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ==================== Funções de Carregamento e Pré-processamento ====================\n",
    "def normalizar_dados(entradas):\n",
    "    # Normalização: traz os dados para a mesma escala\n",
    "    desvio_padrao = entradas.std(axis=0)\n",
    "    desvio_padrao[desvio_padrao == 0] = 1  # Evita divisão por zero\n",
    "    return (entradas - entradas.mean(axis=0)) / desvio_padrao\n",
    "\n",
    "# ==================== Execução do Modelo ====================\n",
    "# 1. Carregar os dados de treinamento\n",
    "caminho_arquivo_treino = 'train_esrb_rating.csv'\n",
    "dados = pd.read_csv(caminho_arquivo_treino)\n",
    "\n",
    "# Separar entradas e rótulos\n",
    "entradas = dados.iloc[:, :-1].values  # Todas as colunas, exceto a última\n",
    "rotulos = dados.iloc[:, -1].values    # Última coluna (os rótulos de classe)\n",
    "\n",
    "# 2. Pré-processamento para os dados de treinamento\n",
    "entradas_normalizadas = normalizar_dados(entradas)\n",
    "rotulos_one_hot = pd.get_dummies(rotulos).values  # One-hot encoding para as classes\n",
    "\n",
    "# 3. Definir a arquitetura da rede neural\n",
    "tamanho_entrada = entradas_normalizadas.shape[1]\n",
    "tamanho_saida = rotulos_one_hot.shape[1]\n",
    "camadas_ocultas = [10, 10, 10]  # Número de neurônios nas camadas ocultas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oHy4-y4YF-rD"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Inicializar a rede neural\n",
    "nn = ClassificacaoMulticlasse(tamanho_entrada, camadas_ocultas, tamanho_saida)\n",
    "\n",
    "# 4. Carregar os dados de teste\n",
    "caminho_arquivo_teste = 'test_esrb_rating.csv'\n",
    "dados_teste = pd.read_csv(caminho_arquivo_teste)\n",
    "\n",
    "# Separar entradas e rótulos para o teste\n",
    "entradas_teste = dados_teste.iloc[:, :-1].values\n",
    "rotulos_teste = dados_teste.iloc[:, -1].values\n",
    "\n",
    "# 5. Pré-processamento para os dados de teste\n",
    "entradas_teste_normalizadas = normalizar_dados(entradas_teste)\n",
    "rotulos_teste_one_hot = pd.get_dummies(rotulos_teste).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hYjVMbfQF-rE",
    "outputId": "b3351ca2-a79c-476f-83b6-88e4d04998ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 0, Custo: 1.5641, Acurácia: 25.50% Precisão no treino: 17.45%, Recall: 22.01%, F1-score: 19.32%\n",
      "Época 100, Custo: 1.2082, Acurácia: 53.80% Precisão no treino: 53.03%, Recall: 51.20%, F1-score: 48.46%\n",
      "Época 200, Custo: 1.0609, Acurácia: 62.46% Precisão no treino: 65.72%, Recall: 60.69%, F1-score: 60.03%\n",
      "Época 300, Custo: 0.9253, Acurácia: 66.53% Precisão no treino: 67.12%, Recall: 65.87%, F1-score: 64.99%\n",
      "Época 400, Custo: 0.8068, Acurácia: 69.22% Precisão no treino: 70.25%, Recall: 68.33%, F1-score: 67.67%\n",
      "Época 500, Custo: 0.7144, Acurácia: 76.08% Precisão no treino: 77.36%, Recall: 76.05%, F1-score: 76.37%\n",
      "Época 600, Custo: 0.6419, Acurácia: 77.61% Precisão no treino: 78.60%, Recall: 77.77%, F1-score: 77.96%\n",
      "Época 700, Custo: 0.5824, Acurácia: 81.20% Precisão no treino: 81.89%, Recall: 81.91%, F1-score: 81.89%\n",
      "Época 800, Custo: 0.5374, Acurácia: 82.37% Precisão no treino: 82.75%, Recall: 83.25%, F1-score: 82.98%\n",
      "Época 900, Custo: 0.5011, Acurácia: 83.47% Precisão no treino: 83.94%, Recall: 84.23%, F1-score: 84.08%\n",
      "Época 1000, Custo: 0.4721, Acurácia: 83.95% Precisão no treino: 84.22%, Recall: 84.88%, F1-score: 84.52%\n",
      "Época 1100, Custo: 0.4481, Acurácia: 84.21% Precisão no treino: 84.52%, Recall: 85.03%, F1-score: 84.75%\n",
      "Época 1200, Custo: 0.4280, Acurácia: 84.48% Precisão no treino: 84.85%, Recall: 85.39%, F1-score: 85.09%\n",
      "Época 1300, Custo: 0.4101, Acurácia: 84.53% Precisão no treino: 84.86%, Recall: 85.48%, F1-score: 85.13%\n",
      "Época 1400, Custo: 0.3943, Acurácia: 84.95% Precisão no treino: 85.30%, Recall: 85.96%, F1-score: 85.58%\n",
      "Época 1500, Custo: 0.3808, Acurácia: 85.22% Precisão no treino: 85.58%, Recall: 86.21%, F1-score: 85.84%\n",
      "Época 1600, Custo: 0.3692, Acurácia: 85.96% Precisão no treino: 86.26%, Recall: 87.00%, F1-score: 86.55%\n",
      "Época 1700, Custo: 0.3599, Acurácia: 86.11% Precisão no treino: 86.40%, Recall: 87.13%, F1-score: 86.69%\n",
      "Época 1800, Custo: 0.3520, Acurácia: 86.11% Precisão no treino: 86.49%, Recall: 87.13%, F1-score: 86.74%\n",
      "Época 1900, Custo: 0.3450, Acurácia: 86.69% Precisão no treino: 87.01%, Recall: 87.75%, F1-score: 87.31%\n",
      "Época 2000, Custo: 0.3385, Acurácia: 86.85% Precisão no treino: 87.19%, Recall: 87.86%, F1-score: 87.47%\n",
      "Época 2100, Custo: 0.3329, Acurácia: 87.17% Precisão no treino: 87.51%, Recall: 88.13%, F1-score: 87.77%\n",
      "Época 2200, Custo: 0.3280, Acurácia: 87.54% Precisão no treino: 87.87%, Recall: 88.42%, F1-score: 88.10%\n",
      "Época 2300, Custo: 0.3232, Acurácia: 88.17% Precisão no treino: 88.46%, Recall: 88.97%, F1-score: 88.69%\n",
      "Época 2400, Custo: 0.3190, Acurácia: 88.38% Precisão no treino: 88.67%, Recall: 89.20%, F1-score: 88.90%\n",
      "Época 2500, Custo: 0.3149, Acurácia: 88.44% Precisão no treino: 88.74%, Recall: 89.23%, F1-score: 88.96%\n",
      "Época 2600, Custo: 0.3113, Acurácia: 88.44% Precisão no treino: 88.74%, Recall: 89.23%, F1-score: 88.96%\n",
      "Época 2700, Custo: 0.3080, Acurácia: 88.44% Precisão no treino: 88.74%, Recall: 89.23%, F1-score: 88.96%\n",
      "Época 2800, Custo: 0.3052, Acurácia: 88.86% Precisão no treino: 89.17%, Recall: 89.60%, F1-score: 89.35%\n",
      "Época 2900, Custo: 0.3024, Acurácia: 88.86% Precisão no treino: 89.18%, Recall: 89.60%, F1-score: 89.36%\n",
      "Época 3000, Custo: 0.2997, Acurácia: 88.91% Precisão no treino: 89.23%, Recall: 89.67%, F1-score: 89.41%\n",
      "Época 3100, Custo: 0.2974, Acurácia: 89.02% Precisão no treino: 89.35%, Recall: 89.74%, F1-score: 89.51%\n",
      "Época 3200, Custo: 0.2952, Acurácia: 89.07% Precisão no treino: 89.37%, Recall: 89.80%, F1-score: 89.56%\n",
      "Época 3300, Custo: 0.2933, Acurácia: 89.02% Precisão no treino: 89.32%, Recall: 89.77%, F1-score: 89.51%\n",
      "Época 3400, Custo: 0.2914, Acurácia: 89.02% Precisão no treino: 89.33%, Recall: 89.77%, F1-score: 89.52%\n",
      "Época 3500, Custo: 0.2896, Acurácia: 88.97% Precisão no treino: 89.27%, Recall: 89.75%, F1-score: 89.48%\n",
      "Época 3600, Custo: 0.2878, Acurácia: 88.97% Precisão no treino: 89.27%, Recall: 89.75%, F1-score: 89.48%\n",
      "Época 3700, Custo: 0.2861, Acurácia: 89.07% Precisão no treino: 89.38%, Recall: 89.83%, F1-score: 89.57%\n",
      "Época 3800, Custo: 0.2845, Acurácia: 89.12% Precisão no treino: 89.43%, Recall: 89.86%, F1-score: 89.62%\n",
      "Época 3900, Custo: 0.2828, Acurácia: 89.12% Precisão no treino: 89.43%, Recall: 89.86%, F1-score: 89.62%\n",
      "Época 4000, Custo: 0.2812, Acurácia: 89.18% Precisão no treino: 89.52%, Recall: 89.90%, F1-score: 89.68%\n",
      "Época 4100, Custo: 0.2797, Acurácia: 89.18% Precisão no treino: 89.52%, Recall: 89.90%, F1-score: 89.68%\n",
      "Época 4200, Custo: 0.2782, Acurácia: 89.28% Precisão no treino: 89.61%, Recall: 90.02%, F1-score: 89.78%\n",
      "Época 4300, Custo: 0.2768, Acurácia: 89.28% Precisão no treino: 89.55%, Recall: 90.20%, F1-score: 89.81%\n",
      "Época 4400, Custo: 0.2754, Acurácia: 89.28% Precisão no treino: 89.55%, Recall: 90.20%, F1-score: 89.81%\n",
      "Época 4500, Custo: 0.2741, Acurácia: 89.33% Precisão no treino: 89.62%, Recall: 90.24%, F1-score: 89.87%\n",
      "Época 4600, Custo: 0.2727, Acurácia: 89.33% Precisão no treino: 89.62%, Recall: 90.24%, F1-score: 89.87%\n",
      "Época 4700, Custo: 0.2713, Acurácia: 89.33% Precisão no treino: 89.62%, Recall: 90.24%, F1-score: 89.87%\n",
      "Época 4800, Custo: 0.2700, Acurácia: 89.44% Precisão no treino: 89.71%, Recall: 90.34%, F1-score: 89.96%\n",
      "Época 4900, Custo: 0.2687, Acurácia: 89.49% Precisão no treino: 89.77%, Recall: 90.38%, F1-score: 90.01%\n",
      "Época 4999, Custo: 0.2673, Acurácia: 89.55% Precisão no treino: 89.83%, Recall: 90.39%, F1-score: 90.06%\n",
      "==Teste==\n",
      "Acurácia: 84.57%\n",
      "Precisão: 85.22%\n",
      "Recall: 85.45%\n",
      "F1-Score: 85.29%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. Treinamento do modelo\n",
    "epocas = 5000\n",
    "batch_size = len(entradas_normalizadas)  # Usando todos os dados para o treinamento\n",
    "taxa_aprendizado = 0.01\n",
    "nn.train(entradas_normalizadas, rotulos_one_hot, epocas, batch_size, taxa_aprendizado)\n",
    "\n",
    "# 7. Salvar os pesos após o treinamento\n",
    "seconds = time.time()\n",
    "nn.save_pesos(f'modelo_classificacao_multiclasse-{time.ctime(seconds)}.npz')\n",
    "\n",
    "# 8. Avaliar o modelo com os dados de teste\n",
    "metrics = nn.evaluate(entradas_teste_normalizadas, rotulos_teste_one_hot)\n",
    "print('==Teste==')\n",
    "print(f\"Acurácia: {metrics['Accuracy']:.2%}\")\n",
    "print(f\"Precisão: {metrics['Precision']:.2%}\")\n",
    "print(f\"Recall: {metrics['Recall']:.2%}\")\n",
    "print(f\"F1-Score: {metrics['F1-Score']:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

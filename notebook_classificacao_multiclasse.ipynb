{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descrição do Modelo de Classificação Multiclasse\n",
    "\n",
    "O modelo de classificação multiclasse foi projetado para prever a classe ESRB Rating de jogos com base em diversas características extraídas de um conjunto de dados estruturado. Este dataset contém informações detalhadas sobre os atributos dos jogos, organizados em diversas variáveis que influenciam diretamente sua classificação.\n",
    "Características do Dataset\n",
    "\n",
    "    Variáveis Preditivas:\n",
    "    O conjunto de dados inclui diversas características relacionadas aos jogos, como elementos gráficos, mecânicas, interações e outros fatores que contribuem para a definição da classificação ESRB (Entertainment Software Rating Board). Cada característica é representada numericamente, permitindo análises e previsões quantitativas.\n",
    "\n",
    "    Variável Alvo:\n",
    "        Classificação ESRB: A classificação atribuída a cada jogo, que pode assumir valores como E (Everyone), T (Teen), ou M (Mature), categorizando o público-alvo baseado no conteúdo do jogo.\n",
    "\n",
    "Objetivo do Modelo\n",
    "\n",
    "O objetivo do modelo é prever corretamente a classificação ESRB de um jogo a partir das suas características. Isso permite compreender quais fatores têm maior influência na classificação e otimizar a categorização de novos jogos, contribuindo para a adequação ao público-alvo e conformidade regulatória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# ==================== Classe Classificação Multiclasse ====================\n",
    "class ClassificacaoMulticlasse:\n",
    "    def __init__(self, tamanho_entrada, camadas_ocultas, tamanho_saida):\n",
    "        # Inicializa as camadas da rede neural\n",
    "        self.tamanho_entrada = tamanho_entrada\n",
    "        self.camadas_ocultas = camadas_ocultas\n",
    "        self.tamanho_saida = tamanho_saida\n",
    "        \n",
    "        self.pesos = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # Inicialização das camadas com valores aleatórios\n",
    "        self.pesos.append(np.random.randn(tamanho_entrada, camadas_ocultas[0]) * np.sqrt(2. / tamanho_entrada))\n",
    "        self.biases.append(np.zeros((1, camadas_ocultas[0])))\n",
    "        \n",
    "        for i in range(1, len(camadas_ocultas)):\n",
    "            self.pesos.append(np.random.randn(camadas_ocultas[i-1], camadas_ocultas[i]) * np.sqrt(2. / camadas_ocultas[i-1]))\n",
    "            self.biases.append(np.zeros((1, camadas_ocultas[i])))\n",
    "        \n",
    "        self.pesos.append(np.random.randn(camadas_ocultas[-1], tamanho_saida) * np.sqrt(2. / camadas_ocultas[-1]))\n",
    "        self.biases.append(np.zeros((1, tamanho_saida)))\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def relu_derivada(self, x):\n",
    "        return (x > 0).astype(int)\n",
    "\n",
    "    def softmax(self, x):\n",
    "        # Função softmax para ativação da camada de saída\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    def cross_entropy(self, y_pred, y_true):\n",
    "        # Função de perda: Entropia cruzada\n",
    "        m = y_true.shape[0]\n",
    "        epsilon = 1e-8  # Para evitar log(0)\n",
    "        return -np.sum(y_true * np.log(y_pred + epsilon)) / m\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.activations = []\n",
    "        self.z_values = []\n",
    "        \n",
    "        # Propagação para frente\n",
    "        z = np.dot(X, self.pesos[0]) + self.biases[0]\n",
    "        a = self.relu(z)\n",
    "        self.activations.append(a)\n",
    "        self.z_values.append(z)\n",
    "        \n",
    "        for i in range(1, len(self.camadas_ocultas)):\n",
    "            z = np.dot(self.activations[-1], self.pesos[i]) + self.biases[i]\n",
    "            a = self.relu(z)\n",
    "            self.activations.append(a)\n",
    "            self.z_values.append(z)\n",
    "        \n",
    "        z_output = np.dot(self.activations[-1], self.pesos[-1]) + self.biases[-1]\n",
    "        y_pred = self.softmax(z_output)\n",
    "        self.activations.append(y_pred)\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "    def backpropagate(self, X, y, taxa_aprendizado):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        gradiente_saida = self.activations[-1] - y\n",
    "        # Atualização dos pesos e vieses na camada de saída\n",
    "        self.pesos[-1] -= np.dot(self.activations[-2].T, gradiente_saida) * taxa_aprendizado / m\n",
    "        self.biases[-1] -= np.sum(gradiente_saida, axis=0, keepdims=True) * taxa_aprendizado / m\n",
    "        \n",
    "        gradiente = gradiente_saida\n",
    "        # Retropropagação para as camadas ocultas\n",
    "        for i in range(len(self.camadas_ocultas) - 1, -1, -1):\n",
    "            gradiente = np.dot(gradiente, self.pesos[i+1].T) * self.relu_derivada(self.z_values[i])\n",
    "            if i > 0:\n",
    "                self.pesos[i] -= np.dot(self.activations[i-1].T, gradiente) * taxa_aprendizado / m\n",
    "                self.biases[i] -= np.sum(gradiente, axis=0, keepdims=True) * taxa_aprendizado / m\n",
    "            else:\n",
    "                self.pesos[i] -= np.dot(X.T, gradiente) * taxa_aprendizado / m\n",
    "                self.biases[i] -= np.sum(gradiente, axis=0, keepdims=True) * taxa_aprendizado / m\n",
    "\n",
    "    def train(self, X, y, epocas, batch_size, taxa_aprendizado):\n",
    "        for epoca in range(epocas):\n",
    "            for i in range(0, len(X), batch_size):\n",
    "                X_batch = X[i:i+batch_size]\n",
    "                y_batch = y[i:i+batch_size]\n",
    "                \n",
    "                y_pred = self.forward(X_batch)\n",
    "                custo = self.cross_entropy(y_pred, y_batch)\n",
    "                self.backpropagate(X_batch, y_batch, taxa_aprendizado)\n",
    "            \n",
    "            if epoca % 100 == 0 or epoca == epocas-1:\n",
    "                # Calcular a precisão nos dados de treino durante o treinamento\n",
    "                metrics = self.evaluate(X, y)\n",
    "                print(f'Época {epoca}, Custo: {custo:.4f}, Acurácia: {metrics[\"Accuracy\"]:.2%} Precisão no treino: {metrics[\"Precision\"]:.2%}, Recall: {metrics[\"Recall\"]:.2%}, F1-score: {metrics[\"F1-Score\"]:.2%}')\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        # Avalia a precisão do modelo com métricas adicionais\n",
    "        y_pred = self.forward(X)  # Probabilidades previstas\n",
    "        predictions = np.argmax(y_pred, axis=1)  # Classes previstas\n",
    "        true_labels = np.argmax(y, axis=1)  # Classes reais\n",
    "\n",
    "        # Inicializar variáveis para métricas\n",
    "        classes = np.unique(true_labels)\n",
    "        precisions, recalls, f1_scores = [], [], []\n",
    "\n",
    "        for c in classes:\n",
    "            TP = np.sum((predictions == c) & (true_labels == c))  # Verdadeiros Positivos para a classe c\n",
    "            FP = np.sum((predictions == c) & (true_labels != c))  # Falsos Positivos para a classe c\n",
    "            FN = np.sum((predictions != c) & (true_labels == c))  # Falsos Negativos para a classe c\n",
    "\n",
    "            precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "            recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1_scores.append(f1_score)\n",
    "\n",
    "        # Cálculo das médias (média macro)\n",
    "        avg_precision = np.mean(precisions)\n",
    "        avg_recall = np.mean(recalls)\n",
    "        avg_f1_score = np.mean(f1_scores)\n",
    "        accuracy = np.mean(predictions == true_labels)\n",
    "\n",
    "        # Retorno como dicionário\n",
    "        metrics = {\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': avg_precision,\n",
    "            'Recall': avg_recall,\n",
    "            'F1-Score': avg_f1_score\n",
    "        }\n",
    "        return metrics\n",
    "    \n",
    "    # Salvar pesos e bias\n",
    "    def save_pesos(self, file_path):\n",
    "        # Salva pesos e bias com nomes claros para cada camada\n",
    "        np.savez(file_path, \n",
    "                pesos_0=self.pesos[0], biases_0=self.biases[0],\n",
    "                pesos_1=self.pesos[1], biases_1=self.biases[1],\n",
    "                pesos_2=self.pesos[2], biases_2=self.biases[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==================== Funções de Carregamento e Pré-processamento ====================\n",
    "def normalizar_dados(entradas):\n",
    "    # Normalização: traz os dados para a mesma escala\n",
    "    desvio_padrao = entradas.std(axis=0)\n",
    "    desvio_padrao[desvio_padrao == 0] = 1  # Evita divisão por zero\n",
    "    return (entradas - entradas.mean(axis=0)) / desvio_padrao\n",
    "\n",
    "# ==================== Execução do Modelo ====================\n",
    "# 1. Carregar os dados de treinamento\n",
    "caminho_arquivo_treino = './data/train_esrb_rating.csv'\n",
    "dados = pd.read_csv(caminho_arquivo_treino)\n",
    "\n",
    "# Separar entradas e rótulos\n",
    "entradas = dados.iloc[:, :-1].values  # Todas as colunas, exceto a última\n",
    "rotulos = dados.iloc[:, -1].values    # Última coluna (os rótulos de classe)\n",
    "\n",
    "# 2. Pré-processamento para os dados de treinamento\n",
    "entradas_normalizadas = normalizar_dados(entradas)\n",
    "rotulos_one_hot = pd.get_dummies(rotulos).values  # One-hot encoding para as classes\n",
    "\n",
    "# 3. Definir a arquitetura da rede neural\n",
    "tamanho_entrada = entradas_normalizadas.shape[1]\n",
    "tamanho_saida = rotulos_one_hot.shape[1]\n",
    "camadas_ocultas = [10, 10, 10]  # Número de neurônios nas camadas ocultas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inicializar a rede neural\n",
    "nn = ClassificacaoMulticlasse(tamanho_entrada, camadas_ocultas, tamanho_saida)\n",
    "\n",
    "# 4. Carregar os dados de teste\n",
    "caminho_arquivo_teste = './data/test_esrb_rating.csv'\n",
    "dados_teste = pd.read_csv(caminho_arquivo_teste)\n",
    "\n",
    "# Separar entradas e rótulos para o teste\n",
    "entradas_teste = dados_teste.iloc[:, :-1].values\n",
    "rotulos_teste = dados_teste.iloc[:, -1].values\n",
    "\n",
    "# 5. Pré-processamento para os dados de teste\n",
    "entradas_teste_normalizadas = normalizar_dados(entradas_teste)\n",
    "rotulos_teste_one_hot = pd.get_dummies(rotulos_teste).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Treinamento do modelo\n",
    "epocas = 5000\n",
    "batch_size = len(entradas_normalizadas)  # Usando todos os dados para o treinamento\n",
    "taxa_aprendizado = 0.01\n",
    "nn.train(entradas_normalizadas, rotulos_one_hot, epocas, batch_size, taxa_aprendizado)\n",
    "\n",
    "# 7. Salvar os pesos após o treinamento\n",
    "seconds = time.time()\n",
    "nn.save_pesos(f'modelo_classificacao_multiclasse-{time.ctime(seconds)}.npz')\n",
    "\n",
    "# 8. Avaliar o modelo com os dados de teste\n",
    "metrics = nn.evaluate(entradas_teste_normalizadas, rotulos_teste_one_hot)\n",
    "print('==Teste==')\n",
    "print(f\"Acurácia: {metrics['Accuracy']:.2%}\")\n",
    "print(f\"Precisão: {metrics['Precision']:.2%}\")\n",
    "print(f\"Recall: {metrics['Recall']:.2%}\")\n",
    "print(f\"F1-Score: {metrics['F1-Score']:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo de classificação multiclasse\n",
    "\n",
    "Este notebook utiliza um conjunto de dados que contém informações sobre 1.895 jogos eletrônicos e suas classificações de conteúdo conforme o sistema ESRB (Entertainment Software Rating Board). \n",
    "\n",
    "Objetivo\n",
    "\n",
    "O modelo busca identificar a classificação de um jogo em categorias como \"E\" (Everyone), \"ET\" (Everyone + plus), \"T\" (Teen) e \"M\" (Mature), usando técnicas de aprendizado de máquina. A classificação correta pode ajudar desenvolvedores, distribuidores e consumidores a compreender o público-alvo de um jogo.\n",
    "\n",
    "Estrutura dos Dados\n",
    "\n",
    "Os dados são compostos pelos seguintes atributos:\n",
    "\n",
    "    title \tstring \tName of the game. \t----\n",
    "\n",
    "    console \tint \tThe console on which the game was released. \t0 = PS4 1 = PS4 & Xbox_one\n",
    "\n",
    "    Alcohol_Reference \tint \tReference to and/or images of alcoholic beverages. \t0 = no 1 = yes\n",
    "\n",
    "    Animated_Blood \tint \tDiscolored and/or unrealistic depictions of blood. \t0 = no 1 = yes\n",
    "\n",
    "    Blood \tint \tDepictions of blood. \t0 = no 1 = yes\n",
    "\n",
    "    Blood_and_Gore \tint \tDepictions of blood or the mutilation of body parts. \t0 = no 1 = yes\n",
    "\n",
    "    Cartoon_Violence \tint \tViolent actions involving cartoon-like situations and characters. May include violence where a character is unharmed after the action has been inflicted. \t0 = no 1 = yes\n",
    "\n",
    "    Crude_Humor \tint \tDepictions or dialogue involving vulgar antics, including \"bathroom\" humor. \t0 = no 1 = yes\n",
    "\n",
    "    DrugRe_ference \tint \tReference to and/or images of illegal drugs. \t0 = no 1 = yes\n",
    "\n",
    "    Fantasy_Violence \tint \tViolent actions of a fantasy nature, involving human or non-human characters in situations easily distinguishable from real life. \t0 = no 1 = yes\n",
    "\n",
    "    Intense_Violence \tint \tGraphic and realistic-looking depictions of physical conflict. May involve extreme and/or realistic blood, gore, weapons, and depictions of human injury and death. \t0 = no 1 = yes\n",
    "\n",
    "    Language \tint \tModerate use of profanity. \t0 = no 1 = yes\n",
    "\n",
    "    Lyrics \tint \tReferences to profanity, sexuality, violence, alcohol, or drug use in music. \t0 = no 1 = yes\n",
    "\n",
    "    Mature_Humor \tint \tDepictions or dialogue involving \"adult\" humor, including sexual references. \t0 = no 1 = yes\n",
    "\n",
    "    Mild_Blood \tint \tSome blood. \t0 = no 1 = yes\n",
    "\n",
    "    Mild_Cartoon_Violence \tint \tSome violent actions involving cartoon. \t0 = no 1 = yes\n",
    "\n",
    "    Mild_Fantasy_Violence \tint \tSome violent actions of a fantasy nature. \t0 = no 1 = yes\n",
    "\n",
    "    Mild_Language \tint \tMild to moderate use of profanity. \t0 = no 1 = yes\n",
    "\n",
    "    Mild_Lyrics \tint \tMild References to profanity, sexuality, violence, alcohol, or drug use in music. \t0 = no 1 = yes\n",
    "\n",
    "    Mild_Suggestive_Themes \tint \tsome provocative references or materials \t0 = no 1 = yes\n",
    "\n",
    "    Mild_Violence \tint \tSome scenes involving aggressive conflict. \t0 = no 1 = yes\n",
    "\n",
    "    No_Descriptors \tint \tNo content descriptors. \t0 = no 1 = yes\n",
    "\n",
    "    Nudity \tint \tGraphic or prolonged depictions of nudity. \t0 = no 1 = yes\n",
    "\n",
    "    Partial_Nudity \tint \tBrief and/or mild depictions of nudity. \t0 = no 1 = yes\n",
    "\n",
    "    Sexual_Content \tint \tNon-explicit depictions of sexual behavior, possibly including partial nudity. \t0 = no 1 = yes\n",
    "\n",
    "    Sexual_Themes \tint \tReferences to sex or sexuality. \t0 = no 1 = yes\n",
    "\n",
    "    Simulated_Gambling \tint \tPlayer can gamble without betting or wagering real cash or currency. \t0 = no 1 = yes\n",
    "\n",
    "    Strong_Language \tint \tExplicit and/or frequent use of profanity. \t0 = no 1 = yes\n",
    "\n",
    "    Strong_Sexual_Content \tint \tExplicit and/or frequent depictions of sexual behavior, possibly including nudity. \t0 = no 1 = yes\n",
    "\n",
    "    Suggestive_Themes \tint \tProvocative references or materials. \t0 = no 1 = yes\n",
    "\n",
    "    Use_of_Alcohol \tint \tThe consumption of alcoholic beverages. \t0 = no 1 = yes\n",
    "\n",
    "    Use_of_Drugs_and_Alcohol \tint \tThe consumption of alcoholic and drugs beverages. \t0 = no 1 = yes\n",
    "\n",
    "    Violence \tint \tScenes involving aggressive conflict. May contain bloodless dismemberment. \t0 = no 1 = yes\n",
    "\n",
    "Rotulo\n",
    "\n",
    "    ESRB_rating \tstring \trating: RP - EC - E - E+10 - T - M - A    \tE , ET , T , M\n",
    "\n",
    "Limitações dos Dados\n",
    "\n",
    "Algumas classificações como \"RP\" (Rating Pending), \"EC\" (Early Childhood) e \"A\" (Adults Only) não estão presentes na versão atual do conjunto de dados, limitando a abrangência do modelo.\n",
    "\n",
    "Abordagem\n",
    "\n",
    "Para implementar o modelo foi algoritmos de aprendizado supervisionado para:\n",
    "    \n",
    "    Algoritmo de retropropagação (backpropagation);\n",
    "    Otimização por gradiente descendente.\n",
    "\n",
    "\n",
    "Essa análise pode ser estendida para melhorar recomendações e garantir conformidade com as diretrizes da ESRB. Caso precise de mais informações ou análises, posso ajudar!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# ==================== Classe Classificação Multiclasse ====================\n",
    "class ClassificacaoMulticlasse:\n",
    "    def __init__(self, tamanho_entrada, camadas_ocultas, tamanho_saida):\n",
    "        # Inicializa as camadas da rede neural\n",
    "        self.tamanho_entrada = tamanho_entrada\n",
    "        self.camadas_ocultas = camadas_ocultas\n",
    "        self.tamanho_saida = tamanho_saida\n",
    "        \n",
    "        self.pesos = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # Inicialização das camadas com valores aleatórios\n",
    "        self.pesos.append(np.random.randn(tamanho_entrada, camadas_ocultas[0]) * np.sqrt(2. / tamanho_entrada))\n",
    "        self.biases.append(np.zeros((1, camadas_ocultas[0])))\n",
    "        \n",
    "        for i in range(1, len(camadas_ocultas)):\n",
    "            self.pesos.append(np.random.randn(camadas_ocultas[i-1], camadas_ocultas[i]) * np.sqrt(2. / camadas_ocultas[i-1]))\n",
    "            self.biases.append(np.zeros((1, camadas_ocultas[i])))\n",
    "        \n",
    "        self.pesos.append(np.random.randn(camadas_ocultas[-1], tamanho_saida) * np.sqrt(2. / camadas_ocultas[-1]))\n",
    "        self.biases.append(np.zeros((1, tamanho_saida)))\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def relu_derivada(self, x):\n",
    "        return (x > 0).astype(int)\n",
    "\n",
    "    def softmax(self, x):\n",
    "        # Função softmax para ativação da camada de saída\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    def cross_entropy(self, y_pred, y_true):\n",
    "        # Função de perda: Entropia cruzada\n",
    "        m = y_true.shape[0]\n",
    "        epsilon = 1e-8  # Para evitar log(0)\n",
    "        return -np.sum(y_true * np.log(y_pred + epsilon)) / m\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.activations = []\n",
    "        self.z_values = []\n",
    "        \n",
    "        # Propagação para frente\n",
    "        z = np.dot(X, self.pesos[0]) + self.biases[0]\n",
    "        a = self.relu(z)\n",
    "        self.activations.append(a)\n",
    "        self.z_values.append(z)\n",
    "        \n",
    "        for i in range(1, len(self.camadas_ocultas)):\n",
    "            z = np.dot(self.activations[-1], self.pesos[i]) + self.biases[i]\n",
    "            a = self.relu(z)\n",
    "            self.activations.append(a)\n",
    "            self.z_values.append(z)\n",
    "        \n",
    "        z_output = np.dot(self.activations[-1], self.pesos[-1]) + self.biases[-1]\n",
    "        y_pred = self.softmax(z_output)\n",
    "        self.activations.append(y_pred)\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "    def backpropagate(self, X, y, taxa_aprendizado):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        gradiente_saida = self.activations[-1] - y\n",
    "        # Atualização dos pesos e vieses na camada de saída\n",
    "        self.pesos[-1] -= np.dot(self.activations[-2].T, gradiente_saida) * taxa_aprendizado / m\n",
    "        self.biases[-1] -= np.sum(gradiente_saida, axis=0, keepdims=True) * taxa_aprendizado / m\n",
    "        \n",
    "        gradiente = gradiente_saida\n",
    "        # Retropropagação para as camadas ocultas\n",
    "        for i in range(len(self.camadas_ocultas) - 1, -1, -1):\n",
    "            gradiente = np.dot(gradiente, self.pesos[i+1].T) * self.relu_derivada(self.z_values[i])\n",
    "            if i > 0:\n",
    "                self.pesos[i] -= np.dot(self.activations[i-1].T, gradiente) * taxa_aprendizado / m\n",
    "                self.biases[i] -= np.sum(gradiente, axis=0, keepdims=True) * taxa_aprendizado / m\n",
    "            else:\n",
    "                self.pesos[i] -= np.dot(X.T, gradiente) * taxa_aprendizado / m\n",
    "                self.biases[i] -= np.sum(gradiente, axis=0, keepdims=True) * taxa_aprendizado / m\n",
    "\n",
    "    def train(self, X, y, epocas, batch_size, taxa_aprendizado):\n",
    "        for epoca in range(epocas):\n",
    "            for i in range(0, len(X), batch_size):\n",
    "                X_batch = X[i:i+batch_size]\n",
    "                y_batch = y[i:i+batch_size]\n",
    "                \n",
    "                y_pred = self.forward(X_batch)\n",
    "                custo = self.cross_entropy(y_pred, y_batch)\n",
    "                self.backpropagate(X_batch, y_batch, taxa_aprendizado)\n",
    "            \n",
    "            if epoca % 100 == 0 or epoca == epocas-1:\n",
    "                # Calcular a precisão nos dados de treino durante o treinamento\n",
    "                metrics = self.evaluate(X, y)\n",
    "                print(f'Época {epoca}, Custo: {custo:.4f}, Acurácia: {metrics[\"Accuracy\"]:.2%} Precisão no treino: {metrics[\"Precision\"]:.2%}, Recall: {metrics[\"Recall\"]:.2%}, F1-score: {metrics[\"F1-Score\"]:.2%}')\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        # Avalia a precisão do modelo com métricas adicionais\n",
    "        y_pred = self.forward(X)  # Probabilidades previstas\n",
    "        predictions = np.argmax(y_pred, axis=1)  # Classes previstas\n",
    "        true_labels = np.argmax(y, axis=1)  # Classes reais\n",
    "\n",
    "        # Inicializar variáveis para métricas\n",
    "        classes = np.unique(true_labels)\n",
    "        precisions, recalls, f1_scores = [], [], []\n",
    "\n",
    "        for c in classes:\n",
    "            TP = np.sum((predictions == c) & (true_labels == c))  # Verdadeiros Positivos para a classe c\n",
    "            FP = np.sum((predictions == c) & (true_labels != c))  # Falsos Positivos para a classe c\n",
    "            FN = np.sum((predictions != c) & (true_labels == c))  # Falsos Negativos para a classe c\n",
    "\n",
    "            precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "            recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1_scores.append(f1_score)\n",
    "\n",
    "        # Cálculo das médias (média macro)\n",
    "        avg_precision = np.mean(precisions)\n",
    "        avg_recall = np.mean(recalls)\n",
    "        avg_f1_score = np.mean(f1_scores)\n",
    "        accuracy = np.mean(predictions == true_labels)\n",
    "\n",
    "        # Retorno como dicionário\n",
    "        metrics = {\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': avg_precision,\n",
    "            'Recall': avg_recall,\n",
    "            'F1-Score': avg_f1_score\n",
    "        }\n",
    "        return metrics\n",
    "    \n",
    "    # Salvar pesos e bias\n",
    "    def save_pesos(self, file_path):\n",
    "        # Salva pesos e bias com nomes claros para cada camada\n",
    "        np.savez(file_path, \n",
    "                pesos_0=self.pesos[0], biases_0=self.biases[0],\n",
    "                pesos_1=self.pesos[1], biases_1=self.biases[1],\n",
    "                pesos_2=self.pesos[2], biases_2=self.biases[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==================== Funções de Carregamento e Pré-processamento ====================\n",
    "def normalizar_dados(entradas):\n",
    "    # Normalização: traz os dados para a mesma escala\n",
    "    desvio_padrao = entradas.std(axis=0)\n",
    "    desvio_padrao[desvio_padrao == 0] = 1  # Evita divisão por zero\n",
    "    return (entradas - entradas.mean(axis=0)) / desvio_padrao\n",
    "\n",
    "# ==================== Execução do Modelo ====================\n",
    "# 1. Carregar os dados de treinamento\n",
    "caminho_arquivo_treino = './data/train_esrb_rating.csv'\n",
    "dados = pd.read_csv(caminho_arquivo_treino)\n",
    "\n",
    "# Separar entradas e rótulos\n",
    "entradas = dados.iloc[:, :-1].values  # Todas as colunas, exceto a última\n",
    "rotulos = dados.iloc[:, -1].values    # Última coluna (os rótulos de classe)\n",
    "\n",
    "# 2. Pré-processamento para os dados de treinamento\n",
    "entradas_normalizadas = normalizar_dados(entradas)\n",
    "rotulos_one_hot = pd.get_dummies(rotulos).values  # One-hot encoding para as classes\n",
    "\n",
    "# 3. Definir a arquitetura da rede neural\n",
    "tamanho_entrada = entradas_normalizadas.shape[1]\n",
    "tamanho_saida = rotulos_one_hot.shape[1]\n",
    "camadas_ocultas = [10, 10, 10]  # Número de neurônios nas camadas ocultas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inicializar a rede neural\n",
    "nn = ClassificacaoMulticlasse(tamanho_entrada, camadas_ocultas, tamanho_saida)\n",
    "\n",
    "# 4. Carregar os dados de teste\n",
    "caminho_arquivo_teste = './data/test_esrb_rating.csv'\n",
    "dados_teste = pd.read_csv(caminho_arquivo_teste)\n",
    "\n",
    "# Separar entradas e rótulos para o teste\n",
    "entradas_teste = dados_teste.iloc[:, :-1].values\n",
    "rotulos_teste = dados_teste.iloc[:, -1].values\n",
    "\n",
    "# 5. Pré-processamento para os dados de teste\n",
    "entradas_teste_normalizadas = normalizar_dados(entradas_teste)\n",
    "rotulos_teste_one_hot = pd.get_dummies(rotulos_teste).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Treinamento do modelo\n",
    "epocas = 5000\n",
    "batch_size = len(entradas_normalizadas)  # Usando todos os dados para o treinamento\n",
    "taxa_aprendizado = 0.01\n",
    "nn.train(entradas_normalizadas, rotulos_one_hot, epocas, batch_size, taxa_aprendizado)\n",
    "\n",
    "# 7. Salvar os pesos após o treinamento\n",
    "seconds = time.time()\n",
    "nn.save_pesos(f'modelo_classificacao_multiclasse-{time.ctime(seconds)}.npz')\n",
    "\n",
    "# 8. Avaliar o modelo com os dados de teste\n",
    "metrics = nn.evaluate(entradas_teste_normalizadas, rotulos_teste_one_hot)\n",
    "print('==Teste==')\n",
    "print(f\"Acurácia: {metrics['Accuracy']:.2%}\")\n",
    "print(f\"Precisão: {metrics['Precision']:.2%}\")\n",
    "print(f\"Recall: {metrics['Recall']:.2%}\")\n",
    "print(f\"F1-Score: {metrics['F1-Score']:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

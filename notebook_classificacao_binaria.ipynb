{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Implementação do Modelo de Classificação Binária:**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zY9lFyrczCWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota 1:** No trecho de código a seguir são importadas as funções e bibliotecas necessárias, definidas as funções de ativação e de perda, bem como definidas a classe que estrutura a rede neural e as funções utilizadas para realizar a propagação para frente, a retropropagação, o treinamento da rede e as previsões utilizando o conjunto de teste:"
      ],
      "metadata": {
        "id": "r_KhNZzU20Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Função de ativação: Sinal\n",
        "def sinal(x):\n",
        "    u = x.item(0)\n",
        "    if x > 0:\n",
        "        return 1;\n",
        "    return -1;\n",
        "\n",
        "\n",
        "# Função de ativação: Sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "# Derivada da função Sigmoid\n",
        "def derivada_sigmoid(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "\n",
        "# Função de ativação: ReLU\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "\n",
        "# Derivada de ReLU\n",
        "def derivada_relu(x):\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "\n",
        "# Função de perda: Entropia Cruzada Binária: calcula a diferença entre os valores reais e previstos no contexto de classificação binária.\n",
        "def entropia_cruzada_binaria(y_verdadeiro, y_predito):\n",
        "\n",
        "    y_predito = np.clip(y_predito, 1e-15, 1 - 1e-15)  # Evitar valores fora da faixa (0, 1)\n",
        "    return -np.mean(y_verdadeiro * np.log(y_predito) + (1 - y_verdadeiro) * np.log(1 - y_predito))\n",
        "\n",
        "\n",
        "# Função de perda: Erro Quadrático Médio (EQM)\n",
        "def eqm(y_verdadeiro, y_predito):\n",
        "    return np.mean((y_verdadeiro - y_predito) ** 2)\n",
        "\n",
        "\n",
        "# Estrutura da Rede Neural\n",
        "class ClassificacaoBinaria:\n",
        "\n",
        "    def __init__(self, entrada_tamanho, oculto_tamanho, saida_tamanho, taxa_aprendizado):\n",
        "\n",
        "        # Número de atributos (colunas de entrada).\n",
        "        self.entrada_tamanho = entrada_tamanho\n",
        "        # Número de neurônios na camada oculta.\n",
        "        self.oculto_tamanho = oculto_tamanho\n",
        "        # Número de classes ou saídas (1 neste caso para classificação binária).\n",
        "        self.saida_tamanho = saida_tamanho\n",
        "        # Taxa para o gradiente descendente.\n",
        "        self.taxa_aprendizado = taxa_aprendizado\n",
        "\n",
        "        # Inicialização dos pesos e vieses com valores aleatórios pequenos\n",
        "        self.pesos_entrada_oculto = np.random.randn(entrada_tamanho, oculto_tamanho) * 0.01\n",
        "        self.vies_oculto = np.zeros((1, oculto_tamanho))\n",
        "        self.pesos_oculto_saida = np.random.randn(oculto_tamanho, saida_tamanho) * 0.01\n",
        "        self.vies_saida = np.zeros((1, saida_tamanho))\n",
        "\n",
        "\n",
        "    # Calcula a saída da rede. Recebe como parâmetro o conjunto de dados de entrada.\n",
        "    def propagacao_frente(self, entrada):\n",
        "\n",
        "        # CAMADA 1: Propagação da camada de entrada para a oculta\n",
        "        self.entrada_oculto = np.dot( entrada, self.pesos_entrada_oculto ) + self.vies_oculto\n",
        "        self.saida_oculto = sigmoid( self.entrada_oculto )\n",
        "\n",
        "        # CAMADA 2: Propagação da camada oculta para a camada de saída\n",
        "        self.entrada_saida = np.dot( self.saida_oculto, self.pesos_oculto_saida ) + self.vies_saida\n",
        "        self.saida_final = sigmoid( self.entrada_saida )\n",
        "\n",
        "        return self.saida_final\n",
        "\n",
        "\n",
        "    # Executa retropropagação (backpropagation) para atualizar os pesos.\n",
        "    # - entrada: dados de entrada.\n",
        "    # - y_verdadeiro: valores reais\n",
        "    # - saida: saída gerada pela rede.\n",
        "    def retropropagacao(self, entrada, y_verdadeiro, saida):\n",
        "\n",
        "        # Calcula o erro da saída\n",
        "        erro = y_verdadeiro - saida\n",
        "\n",
        "        # Calcula o gradiente na camada de saída\n",
        "        gradiente_saida = erro * derivada_sigmoid(saida)\n",
        "\n",
        "        # Calcula o erro e o gradiente na camada oculta\n",
        "        erro_oculto = np.dot( gradiente_saida, self.pesos_oculto_saida.T )\n",
        "        gradiente_oculto = erro_oculto * derivada_sigmoid(self.saida_oculto)\n",
        "\n",
        "        # Atualização dos pesos e vieses entre a camada oculta e a saída\n",
        "        gradiente_pesos_saida = np.dot( self.saida_oculto.T, gradiente_saida )  # Matriz de ajustes para pesos\n",
        "        gradiente_vies_saida = np.sum( gradiente_saida, axis=0, keepdims=True )  # Vetor de ajustes para vieses\n",
        "        self.pesos_oculto_saida += gradiente_pesos_saida * self.taxa_aprendizado\n",
        "        self.vies_saida += gradiente_vies_saida * self.taxa_aprendizado\n",
        "\n",
        "        # Atualização dos pesos e vieses entre a camada de entrada e a oculta\n",
        "        gradiente_pesos_oculto = np.dot (entrada.T, gradiente_oculto )  # Matriz de ajustes para pesos\n",
        "        gradiente_vies_oculto = np.sum( gradiente_oculto, axis=0, keepdims=True )  # Vetor de ajustes para vieses\n",
        "        self.pesos_entrada_oculto += gradiente_pesos_oculto * self.taxa_aprendizado\n",
        "        self.vies_oculto += gradiente_vies_oculto * self.taxa_aprendizado\n",
        "\n",
        "\n",
        "    # Treina a rede neural por um número determinado de épocas.\n",
        "    def treinar(self, entrada, y_verdadeiro, epocas):\n",
        "        print()\n",
        "        perdas = []\n",
        "        for epoca in range(epocas):\n",
        "            saida = self.propagacao_frente(entrada)\n",
        "            # Calcula a perda (erro) da rede usando a função de perda de entropia cruzada binária\n",
        "            perda = entropia_cruzada_binaria(y_verdadeiro, saida)\n",
        "            # Calcula a perda (erro) da rede usando a função de perda de erro quadrático médio\n",
        "            # perda = eqm(y_verdadeiro, saida)\n",
        "            perdas.append(perda)\n",
        "            self.retropropagacao(entrada, y_verdadeiro, saida)\n",
        "            if epoca % 200 == 0:\n",
        "                print(\"Época \" + str(epoca) + \", Perda: \" + \"{:.4f}\".format(perda))\n",
        "        return perdas\n",
        "\n",
        "\n",
        "    # Realiza previsões para o conjunto de entrada.\n",
        "    def prever(self, entrada):\n",
        "        saida = self.propagacao_frente(entrada)\n",
        "        return np.round(saida)"
      ],
      "metadata": {
        "id": "ilno25Zi_O_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Nota 2:** A seguir é realizado o carregamento do conjunto de dados utilizado, o qual foi obtido em https://www.kaggle.com/datasets/uom190346a/water-quality-and-potability. Esse conjunto contém medições de qualidade da água e avaliações relacionadas à potabilidade. Colunas disponíveis:\n",
        "\n",
        "   1. pH: nível de pH da água.\n",
        "   2. Hardness: dureza da água, uma medida do conteúdo mineral.\n",
        "   3. Solids: total de sólidos dissolvidos na água.\n",
        "   4. Chloramines: concentração de cloraminas na água.\n",
        "   5. Sulfate: concentração de sulfato na água.\n",
        "   6. Conductivity: condutividade elétrica da água.\n",
        "   7. Organic carbon: conteúdo de carbono orgânico na água.\n",
        "   8. Trihalomethanes: concentração de trihalometanos na água.\n",
        "   9. Turbidity: nível de turbidez, uma medida da clareza da água.\n",
        "   10. Potability: variável alvo; indica potabilidade da água com valores 1 (potável) e 0 (não potável)."
      ],
      "metadata": {
        "id": "xnlnfGmS31Er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregamento do conjunto de dados\n",
        "print(\"Por favor, faça o upload do arquivo 'water_potability.csv'\")\n",
        "arquivo = files.upload()\n",
        "dados = pd.read_csv(\"water_potability.csv\")\n",
        "\n",
        "# Fonte: https://www.kaggle.com/datasets/uom190346a/water-quality-and-potability\n",
        "#:: Variáveis independentes:\n",
        "#   1. pH: nível de pH da água.\n",
        "#   2. Hardness: dureza da água, uma medida do conteúdo mineral.\n",
        "#   3. Solids: total de sólidos dissolvidos na água.\n",
        "#   4. Chloramines: concentração de cloraminas na água.\n",
        "#   5. Sulfate: concentração de sulfato na água.\n",
        "#   6. Conductivity: condutividade elétrica da água.\n",
        "#   7. Organic carbon: conteúdo de carbono orgânico na água.\n",
        "#   8. Trihalomethanes: concentração de trihalometanos na água.\n",
        "#   9. Turbidity: nível de turbidez, uma medida da clareza da água.\n",
        "#:: Variável dependente:\n",
        "#   10. Potability: variável alvo; indica potabilidade da água com valores 1 (potável) e 0 (não potável)."
      ],
      "metadata": {
        "id": "W1dTBkY4A4yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota 3:** Vários registros desse conjunto possuiam valores de variáveis vazios. Foi decidido, então, remover as linhas com valores nulos."
      ],
      "metadata": {
        "id": "COfr_J0J49KL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurações para evitar quebras de linha ao exibir matrizes (arrays)\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.width\", 1000)\n",
        "np.set_printoptions(linewidth=np.inf)\n",
        "\n",
        "print(\"\\nTamanho original do conjunto de dados (linhas, colunas): \", dados.shape)\n",
        "\n",
        "# Remove linhas com valores nulos\n",
        "dados.dropna(inplace=True)\n",
        "\n",
        "print(\"\\nTamanho após remoção de linhas com valores nulos (linhas, colunas): \", dados.shape)\n",
        "\n",
        "# Primeiros 10 registros do conjunto de dados\n",
        "print(\"\\n Primeiros 10 registros (matriz 10x10) do conjunto de dados:\\n\", dados.head(10))"
      ],
      "metadata": {
        "id": "jeRTC9gCBQeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separa o conjunto entre variáveis de entrada/independentes (X) e variável alvo/dependente (y)\n",
        "X = dados.drop(columns=\"Potability\").values\n",
        "y = dados[\"Potability\"].values.reshape(-1, 1)\n",
        "\n",
        "# Normalização dos dados para trazer todas as variáveis para a mesma escala\n",
        "normalizador = StandardScaler()\n",
        "X = normalizador.fit_transform(X)\n",
        "\n",
        "# Divisão dos dados entre treino e teste na proporção de 85/15\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.15, random_state=777)\n",
        "\n",
        "print(\"\\nPrimeiras 10 linhas de X_treino (conjunto de TREINO), de um total de \", X_treino.shape[0], \" linhas, seguidas pelo vetor de variáveis dependentes (y_treino):\")\n",
        "print(X_treino[:10])\n",
        "print(y_treino[:10])\n",
        "\n",
        "print(\"\\nPrimeiras 10 linhas de X_teste (conjunto de TESTE), de um total de \", X_teste.shape[0], \" linhas, seguidas pelo vetor de variáveis dependentes (y_teste):\")\n",
        "print(X_teste[:10])\n",
        "print(y_teste[:10])"
      ],
      "metadata": {
        "id": "ojKzTKi0_kRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação da Rede Neural de Classificação Binária: entrada_tamanho, oculto_tamanho, saida_tamanho, taxa_aprendizado=0.01:\n",
        "rede_Class_Binaria = ClassificacaoBinaria(X_treino.shape[1], 10, 1, 0.01)\n",
        "\n",
        "# Treinamento da Rede Neural\n",
        "perdas = rede_Class_Binaria.treinar(X_treino, y_treino, epocas=5001)\n",
        "\n",
        "# Avaliação da Rede Neural\n",
        "y_predito = rede_Class_Binaria.prever(X_teste)\n",
        "\n",
        "# Calcula o total de previsões corretas\n",
        "previsoes_corretas = 0\n",
        "for yreal, ypred in zip(y_teste, y_predito):\n",
        "    if yreal == ypred:\n",
        "        previsoes_corretas += 1\n",
        "\n",
        "print(\"\\n:: Métricas de Avaliação do Modelo:\")\n",
        "# Acurácia\n",
        "acuracia = previsoes_corretas / len(y_teste)\n",
        "print(\" - Acurácia: {:.4f}\".format(acuracia))\n",
        "\n",
        "# Precisão\n",
        "vp = np.sum((y_teste == 1) & (y_predito == 1))  # Verdadeiros positivos\n",
        "fp = np.sum((y_teste == 0) & (y_predito == 1))  # Falsos positivos\n",
        "precisao = vp / (vp + fp) if (vp + fp) != 0 else 0\n",
        "print(\" - Precisão: {:.4f}\".format(precisao))\n",
        "\n",
        "# Recall\n",
        "vp = np.sum((y_teste == 1) & (y_predito == 1))  # Verdadeiros positivos\n",
        "fn = np.sum((y_teste == 1) & (y_predito == 0))  # Falsos negativos\n",
        "recall = vp / (vp + fn) if (vp + fn) != 0 else 0\n",
        "print(\" - Recall: {:.4f}\".format(recall))\n",
        "\n",
        "# F1-Score\n",
        "f1_score = 2 * (precisao * recall) / (precisao + recall) if (precisao + recall) != 0 else 0\n",
        "print(\" - F1-Score: {:.4f}\".format(f1_score))\n",
        "\n",
        "# Exibe a curva de perda\n",
        "plt.plot(perdas)\n",
        "plt.title(\"Perda ao longo das épocas\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"Perda\")\n",
        "plt.show()\n",
        "print()"
      ],
      "metadata": {
        "id": "gbC4FvVmBZLM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
